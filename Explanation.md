# Financial RAG System : Endâ€‘toâ€‘End Architecture (Inâ€‘Depth)

This document explains the **complete architecture** of the financial questionâ€‘answering system.

The system is divided into **two major macroâ€‘pipelines**:

1. **Offline / Buildâ€‘Time Pipeline**
   (Data â†’ Embeddings â†’ PCA â†’ FAISS Indexes)
2. **Online / Runtime Pipeline**
   (Query â†’ Intent â†’ Retrieval â†’ Generation)

Each macroâ€‘pipeline is itself composed of **smaller, wellâ€‘defined subâ€‘architectures**.

---

## PIPELINE A  OFFLINE BUILD PIPELINE

> **Goal:** Convert raw financial data into optimized vector indexes ready for fast semantic search.

This pipeline is **deterministic, repeatable, and costâ€‘sensitive**.
It is executed **once** or on data refresh â€” **never per user query**.

---

## A1. Raw Data Ingestion Architecture

```text
CSV Files
â”œâ”€â”€ trades.csv
â””â”€â”€ holdings.csv
        â†“
Pandas DataFrames
```

**Key properties**:

* Data is treated as the **source of truth**
* No LLM involvement
* No transformation beyond loading

---

## A2. Schema Validation & Data Discipline Layer

```text
Raw DataFrame
      â†“
Schema Validator
      â†“
Validated DataFrame
```

**What happens here:**

* Mandatory column presence checks
* Strict date parsing (`TradeDate`, `AsOfDate`)
* Numeric enforcement (`Quantity`, `Price`, `Qty`, `MV_Base`, `PL_YTD`)
* Null rejection in critical fields

**Special handling (Trades):**

```text
Price â‰¤ 0
   â†“
Quarantine â†’ trades_quarantine.csv
```

This ensures:

* Invalid financial records never pollute embeddings
* Auditability is preserved

---

## A3. Semantic Row Serialization Layer

```text
Validated Rows
      â†“
Row â†’ Naturalâ€‘Language Description
      â†“
semantic_core (string)
```

Each row is converted into a **selfâ€‘contained semantic sentence**.

Example (Trades):

```
Trade event on 2024â€‘01â€‘15 for AlphaFund: BUY 100 units of AAPL at price 187.5 strategy Momentum
```

Example (Holdings):

```
Holding position as of 2024â€‘01â€‘31 for AlphaFund: Held 250 units of AAPL valued at 46875 with YTD P&L 4200
```

**Why this matters:**

* Vector embeddings operate on *meaning*, not tables
* Each row becomes independently searchable

---

## A4. Embedding Generation Architecture (Batchâ€‘Optimized)

```text
semantic_core strings
      â†“
Batching (20 items)
      â†“
Gemini Embedding API
      â†“
float32 vectors
```

**Key optimizations:**

* Controlled batch size (freeâ€‘tier safe)
* Retry with backoff
* Dummy vector fallback to preserve row alignment

Vectors are persisted as:

```
vectors/float/
â”œâ”€â”€ trades_embeddings.pkl
â””â”€â”€ holdings_embeddings.pkl
```

This acts as a **safety checkpoint**.

---

## A5. Dimensionality Reduction (PCA via FAISS)

```text
768â€‘D Embeddings
      â†“
FAISS PCA Training
      â†“
256â€‘D Embeddings
```

**Important properties:**

* PCA is trained **once**
* Same transform applied to trades & holdings
* Stored using FAISS native format

Output:

```
vectors/pca_transform.faiss
```

---

## A6. Vector Indexing (IVF + PQ)

```text
PCA Vectors
      â†“
IVF Partitioning (nlist=64)
      â†“
Product Quantization (m=32, 8â€‘bit)
      â†“
FAISS Indexes
```

Two independent indexes are built:

```
vectors/
â”œâ”€â”€ trades_index/index_pq.faiss
â””â”€â”€ holdings_index/index_pq.faiss
```

**Why separate indexes:**

* Avoids crossâ€‘domain noise
* Enables intentâ€‘based routing
* Improves precision

---

## RESULT OF MACRO PIPELINE A

At this point, the system has:

* Clean validated data
* Semantic text per row
* Optimized vector embeddings
* Searchâ€‘ready FAISS indexes

The system is now **halfâ€‘ready**.

---

# PIPELINE B- ONLINE QUERY PIPELINE

> **Goal:** Answer user questions using only indexed financial data â€” safely and deterministically.

This pipeline runs **per user query**.

---

## B1. User Query Intake

```text
User Question
      â†“
Raw Query String
```

No preprocessing, no assumptions.

---

## B2. Semantic Caching Architecture (Redis)

```text
Query
  â†“
Hash(query)
  â†“
Redis Lookup
```

Cached artifacts:

* Query embeddings
* (Optionally) answers

**Outcome paths:**

```
Cache Hit  â†’ Skip expensive calls
Cache Miss â†’ Continue pipeline
```

---

## B3. Intent Detection & Routing Logic

```text
Query
  â†“
Heuristic Rules
  â†“ (fallback)
Gemini Flash Classifier
  â†“
Intent Plan
```

Possible intents:

* `TRADE_ONLY`
* `HOLDING_ONLY`
* `MIXED`
* `UNSUPPORTED`

The intent directly controls **which FAISS indexes are queried**.

---

## B4. Query Embedding & PCA Projection

```text
Query Text
      â†“
Embedding Model
      â†“
768â€‘D Vector
      â†“
PCA Transform
      â†“
256â€‘D Vector
```

This ensures **query vectors live in the same space** as indexed data.

---

## B5. FAISS Retrieval Architecture

```text
Query Vector
      â†“
FAISS Search (nprobe=8)
      â†“
Topâ€‘K Row IDs
```

Separate searches occur for:

* Trades index
* Holdings index

Only indexes allowed by intent are queried.

---

## B6. Context Reconstruction Layer

```text
Row IDs
      â†“
CSV Row Lookup
      â†“
Textual Context Blocks
```

Context is reconstructed using **original validated CSV rows** â€” not embeddings.

This guarantees:

* Numerical accuracy
* No hallucinated values

---

## B7. Answer Generation (Guarded RAG)

```text
Question + Context
      â†“
Strict Prompt
      â†“
Gemini Flash
      â†“
Final Answer
```

**Hard rule:**
If context is empty or insufficient:

```
"Sorry can not find the answer"
```

No guessing. No external knowledge.

---

## RESULT OF MACRO PIPELINE B

The system produces:

* Contextâ€‘grounded answers
* Or explicit refusal when data is absent

---

# COMPLETE SYSTEM : COMPILED VIEW

```text
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   OFFLINE PIPELINE (A)    â”‚
                â”‚                           â”‚
Raw CSV â”€â”€â–º Validate â”€â”€â–º Serialize â”€â”€â–º Embed â”€â”€â–º PCA â”€â”€â–º FAISS
                â”‚                           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â”‚ (Indexes + PCA)
                                â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   ONLINE PIPELINE (B)     â”‚
                â”‚                           â”‚
User Query â”€â”€â–º Cache â”€â”€â–º Intent â”€â”€â–º Embed â”€â”€â–º Search â”€â”€â–º Context â”€â”€â–º Answer
                â”‚                           â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸŽ¯ Final Engineering Characteristics

* **Deterministic** (no agent chaos)
* **Auditable** (CSV â†’ Answer traceable)
* **Costâ€‘efficient** (batching, caching, PQ)
* **Scalable** (separate offline/online paths)
* **Productionâ€‘safe** (no hallucination paths)

---

## ðŸ“Œ Mental Model (Oneâ€‘Line)

> **LLMs talk. FAISS searches. Pandas computes. Rules decide.**

This architecture reflects that principle endâ€‘toâ€‘end.

---

**Thankyou so much for giving your time to read this, Have a great time ahead :)**
