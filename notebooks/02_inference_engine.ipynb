{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a26732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Setup\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "import redis\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import faiss\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import embed_content\n",
    "\n",
    "from typing import Dict, Any, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "\n",
    "API_KEY = 'your-api-key-here'\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "GEN_MODEL = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "EMBED_MODEL = \"models/text-embedding-004\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd697822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DIR_VECTORS = \"../vectors\"\n",
    "DIR_PROCESSED = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis Setup\n",
    "\n",
    "redis_client = redis.Redis( \n",
    "                            host=\"localhost\",\n",
    "                            port=6379, db=0, \n",
    "                            decode_responses=False)\n",
    "\n",
    "assert redis_client.ping(), \"Redis is not running!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e4600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading System Assets\n"
     ]
    }
   ],
   "source": [
    "# Load Assets (Global State)\n",
    "\n",
    "print(\"Loading System Assets\")\n",
    "\n",
    "# Load Vector Transforms & Indexes\n",
    "\n",
    "pca = faiss.read_VectorTransform(f\"{DIR_VECTORS}/pca_transform.faiss\")\n",
    "\n",
    "trades_index = faiss.read_index(f\"{DIR_VECTORS}/trades_index/index_pq.faiss\")\n",
    "\n",
    "holdings_index = faiss.read_index(f\"{DIR_VECTORS}/holdings_index/index_pq.faiss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09956dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validated Data (For Context Mapping)\n",
    "\n",
    "trades_data = pd.read_csv(f\"{DIR_PROCESSED}/trades_validated.csv\")\n",
    "\n",
    "holdings_data = pd.read_csv(f\"{DIR_PROCESSED}/holdings_validated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "894c89b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assets Loaded.\n"
     ]
    }
   ],
   "source": [
    "# Set Search Depth\n",
    "\n",
    "trades_index.nprobe = 8\n",
    "\n",
    "holdings_index.nprobe = 8\n",
    "\n",
    "print(\"Assets Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching Logic\n",
    "\n",
    "PIPELINE_VER = \"v3\"\n",
    "\n",
    "def build_cache_key(prefix: str, payload: Dict[str, Any]) -> str:\n",
    "\n",
    "    \"\"\"Creates a deterministic hash for Redis keys.\"\"\"\n",
    "\n",
    "    raw = json.dumps(payload, sort_keys=True)\n",
    "\n",
    "    digest = hashlib.sha256(raw.encode()).hexdigest()\n",
    "    \n",
    "    return f\"{prefix}:{PIPELINE_VER}:{digest}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89ab009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(query: str) -> np.ndarray:\n",
    "\n",
    "    \"\"\"Checks Redis for embedding before calling API.\"\"\"\n",
    "\n",
    "    key = build_cache_key(\"query_embedding\", {\"query\": query})\n",
    "    \n",
    "    # Cache Hit\n",
    "\n",
    "    cached = redis_client.get(key)\n",
    "    if cached: \n",
    "        return pickle.loads(cached)\n",
    "    \n",
    "    # Cache Miss\n",
    "\n",
    "    res = embed_content(model=EMBED_MODEL, content=query)\n",
    "    vec = np.array(res[\"embedding\"], dtype=\"float32\")\n",
    "    \n",
    "    # Store in Redis (24h expiry)\n",
    "    \n",
    "    redis_client.set(key, pickle.dumps(vec), ex=86400)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent Classification\n",
    "\n",
    "INTENT_PROMPT = \"\"\"\n",
    "                   \n",
    "You are a STRICT intent classification engine for a financial analytics system.\n",
    "\n",
    "IMPORTANT CONTEXT:\n",
    "- The system has ONLY TWO datasets:\n",
    "  1) Trades data (executed buy/sell transactions)\n",
    "  2) Holdings data (current positions / portfolio holdings)\n",
    "- You do NOT have access to the internet.\n",
    "- You must NOT use any external or general knowledge.\n",
    "- If the question cannot be answered using ONLY these datasets, it is UNSUPPORTED.\n",
    "\n",
    "YOUR TASK:\n",
    "Classify the user's query into EXACTLY ONE of the following intent labels.\n",
    "\n",
    "INTENT DEFINITIONS:\n",
    "\n",
    "TRADE_ONLY:\n",
    "- Questions ONLY about executed trades or transactions\n",
    "- Examples:\n",
    "  - number of trades\n",
    "  - buy/sell activity\n",
    "  - transaction counts\n",
    "  - trade history\n",
    "  - trade performance\n",
    "\n",
    "HOLDING_ONLY:\n",
    "- Questions ONLY about current holdings or positions\n",
    "- Examples:\n",
    "  - current portfolio positions\n",
    "  - holdings value\n",
    "  - securities currently held\n",
    "  - NAV / portfolio value (if derived from holdings)\n",
    "\n",
    "MIXED:\n",
    "- Questions that REQUIRE BOTH:\n",
    "  - trade information AND\n",
    "  - holding information\n",
    "- Examples:\n",
    "  - impact of trades on current holdings\n",
    "  - how transactions changed positions\n",
    "  - relationship between trades and holdings\n",
    "\n",
    "UNSUPPORTED:\n",
    "- Questions that CANNOT be answered from trades or holdings data\n",
    "- Examples:\n",
    "  - company executives\n",
    "  - market news\n",
    "  - predictions\n",
    "  - external facts\n",
    "  - vague or unrelated questions\n",
    "\n",
    "USER QUERY:\n",
    "\"{query}\"\n",
    "\n",
    "OUTPUT RULES (VERY IMPORTANT):\n",
    "- Output ONLY ONE label\n",
    "- Output must be EXACTLY one of:\n",
    "  TRADE_ONLY, HOLDING_ONLY, MIXED, UNSUPPORTED\n",
    "- Do NOT explain your reasoning\n",
    "- Do NOT add extra text\n",
    "- Do NOT add punctuation\n",
    "\"\"\"\n",
    "\n",
    "def resolve_intent(query: str) -> Dict[str, Any]:\n",
    "\n",
    "    \"\"\"Determines which datasets to query.\"\"\"\n",
    "\n",
    "    q_lower = query.lower()\n",
    "    \n",
    "    # Fast Path (Rule-Based)\n",
    "\n",
    "    if \"trade\" in q_lower and \"holding\" in q_lower:\n",
    "        return {\"intent\": \"MIXED\", \"use_trades\": True, \"use_holdings\": True}\n",
    "    \n",
    "    # Slow Path (LLM)\n",
    "    \n",
    "    res = GEN_MODEL.generate_content(INTENT_PROMPT.format(query=query))\n",
    "    intent = res.text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"intent\": intent,\n",
    "        \"use_trades\": intent in [\"TRADE_ONLY\", \"MIXED\"],\n",
    "        \"use_holdings\": intent in [\"HOLDING_ONLY\", \"MIXED\"]\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5a51d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Vector Retrieval\n",
    "def retrieve_context(query: str, plan: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"Fetches relevant rows from CSVs based on vector similarity.\"\"\"\n",
    "    \n",
    "    # 1. Embed & Reduce\n",
    "    query_emb = get_query_embedding(query)\n",
    "    query_pca = pca.apply_py(query_emb.reshape(1, -1))\n",
    "    \n",
    "    context_lines = []\n",
    "    \n",
    "    # 2. Search Trades\n",
    "    if plan['use_trades']:\n",
    "        distances, indices = trades_index.search(query_pca, k=5)\n",
    "        for idx in indices[0]:\n",
    "            if idx != -1:\n",
    "                row_str = trades_data.iloc[idx].to_string()\n",
    "                context_lines.append(f\"TRADE DATA:\\n{row_str}\")\n",
    "\n",
    "    # 3. Search Holdings\n",
    "    if plan['use_holdings']:\n",
    "        distances, indices = holdings_index.search(query_pca, k=5)\n",
    "        for idx in indices[0]:\n",
    "            if idx != -1:\n",
    "                row_str = holdings_data.iloc[idx].to_string()\n",
    "                context_lines.append(f\"HOLDING DATA:\\n{row_str}\")\n",
    "                \n",
    "    return \"\\n---\\n\".join(context_lines) if context_lines else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5191503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation Layer\n",
    "\n",
    "ANSWER_PROMPT = \"\"\"\n",
    "You are a financial assistant. Use ONLY the context below. \n",
    "If the answer is not in the context, say \"Sorry can not find the answer\".\n",
    "Do not make assumptions.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "def generate_answer(query: str) -> str:\n",
    "\n",
    "    \"\"\"Orchestrates Plan -> Retrieve -> Generate.\"\"\"\n",
    "    \n",
    "    # Step 1: Intent\n",
    "\n",
    "    plan = resolve_intent(query)\n",
    "\n",
    "    if plan['intent'] == \"UNSUPPORTED\":\n",
    "        return \"Sorry can not find the answer\"\n",
    "        \n",
    "    # Step 2: Retrieve\n",
    "\n",
    "    context_text = retrieve_context(query, plan)\n",
    "\n",
    "    if not context_text:\n",
    "        return \"Sorry can not find the answer\"\n",
    "        \n",
    "    # Step 3: Generate\n",
    "\n",
    "    prompt = ANSWER_PROMPT.format(context=context_text, question=query)\n",
    "\n",
    "    try:\n",
    "        response = GEN_MODEL.generate_content(prompt)\n",
    "        return response.text.strip()\n",
    "    \n",
    "    except Exception:\n",
    "        return \"Sorry can not find the answer\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0624440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Financial Engine Ready. Type 'exit' to quit.\n",
      "Answer: Sorry can not find the answer\n"
     ]
    }
   ],
   "source": [
    "# Interactive Loop\n",
    "print(\"Financial Engine Ready. Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter Query: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "        \n",
    "    answer = generate_answer(user_input)\n",
    "    print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
