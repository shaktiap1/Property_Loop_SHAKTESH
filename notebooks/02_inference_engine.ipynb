{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a26732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & Setup\n",
    "\n",
    "import os\n",
    "\n",
    "import json\n",
    "import redis\n",
    "\n",
    "import pickle\n",
    "import hashlib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import faiss\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.generativeai import embed_content\n",
    "\n",
    "from typing import Dict, Any, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f3760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration \n",
    "\n",
    "API_KEY = 'AIzaSyAuqlzUOm5RFsSfUDa0iUUeaYv8U7UmQgI'\n",
    "\n",
    "genai.configure(api_key=API_KEY)\n",
    "\n",
    "GEN_MODEL = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "EMBED_MODEL = \"models/text-embedding-004\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd697822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "DIR_VECTORS = \"../vectors\"\n",
    "DIR_PROCESSED = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177f3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis Setup\n",
    "\n",
    "redis_client = redis.Redis( \n",
    "                            host=\"localhost\",\n",
    "                            port=6379, db=0, \n",
    "                            decode_responses=False)\n",
    "\n",
    "assert redis_client.ping(), \"Redis is not running!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5e4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Assets (Global State)\n",
    "\n",
    "print(\"Loading System Assets\")\n",
    "\n",
    "# Load Vector Transforms & Indexes\n",
    "\n",
    "pca = faiss.read_VectorTransform(f\"{DIR_VECTORS}/pca_transform.faiss\")\n",
    "\n",
    "trades_index = faiss.read_index(f\"{DIR_VECTORS}/trades_index/index_pq.faiss\")\n",
    "\n",
    "holdings_index = faiss.read_index(f\"{DIR_VECTORS}/holdings_index/index_pq.faiss\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09956dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Validated Data (For Context Mapping)\n",
    "\n",
    "trades_data = pd.read_csv(f\"{DIR_PROCESSED}/trades_validated.csv\")\n",
    "\n",
    "holdings_data = pd.read_csv(f\"{DIR_PROCESSED}/holdings_validated.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894c89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Search Depth\n",
    "\n",
    "trades_index.nprobe = 8\n",
    "\n",
    "holdings_index.nprobe = 8\n",
    "\n",
    "print(\"Assets Loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefe322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caching Logic\n",
    "\n",
    "PIPELINE_VER = \"v3\"\n",
    "\n",
    "def build_cache_key(prefix: str, payload: Dict[str, Any]) -> str:\n",
    "\n",
    "    \"\"\"Creates a deterministic hash for Redis keys.\"\"\"\n",
    "\n",
    "    raw = json.dumps(payload, sort_keys=True)\n",
    "\n",
    "    digest = hashlib.sha256(raw.encode()).hexdigest()\n",
    "    \n",
    "    return f\"{prefix}:{PIPELINE_VER}:{digest}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89ab009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_query_embedding(query: str) -> np.ndarray:\n",
    "\n",
    "    \"\"\"Checks Redis for embedding before calling API.\"\"\"\n",
    "\n",
    "    key = build_cache_key(\"query_embedding\", {\"query\": query})\n",
    "    \n",
    "    # Cache Hit\n",
    "\n",
    "    cached = redis_client.get(key)\n",
    "    if cached: \n",
    "        return pickle.loads(cached)\n",
    "    \n",
    "    # Cache Miss\n",
    "\n",
    "    res = embed_content(model=EMBED_MODEL, content=query)\n",
    "    vec = np.array(res[\"embedding\"], dtype=\"float32\")\n",
    "    \n",
    "    # Store in Redis (24h expiry)\n",
    "    \n",
    "    redis_client.set(key, pickle.dumps(vec), ex=86400)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ccfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intent Classification\n",
    "\n",
    "INTENT_PROMPT = \"\"\"\n",
    "                   \n",
    "You are a STRICT intent classification engine for a financial analytics system.\n",
    "\n",
    "IMPORTANT CONTEXT:\n",
    "- The system has ONLY TWO datasets:\n",
    "  1) Trades data (executed buy/sell transactions)\n",
    "  2) Holdings data (current positions / portfolio holdings)\n",
    "- You do NOT have access to the internet.\n",
    "- You must NOT use any external or general knowledge.\n",
    "- If the question cannot be answered using ONLY these datasets, it is UNSUPPORTED.\n",
    "\n",
    "YOUR TASK:\n",
    "Classify the user's query into EXACTLY ONE of the following intent labels.\n",
    "\n",
    "INTENT DEFINITIONS:\n",
    "\n",
    "TRADE_ONLY:\n",
    "- Questions ONLY about executed trades or transactions\n",
    "- Examples:\n",
    "  - number of trades\n",
    "  - buy/sell activity\n",
    "  - transaction counts\n",
    "  - trade history\n",
    "  - trade performance\n",
    "\n",
    "HOLDING_ONLY:\n",
    "- Questions ONLY about current holdings or positions\n",
    "- Examples:\n",
    "  - current portfolio positions\n",
    "  - holdings value\n",
    "  - securities currently held\n",
    "  - NAV / portfolio value (if derived from holdings)\n",
    "\n",
    "MIXED:\n",
    "- Questions that REQUIRE BOTH:\n",
    "  - trade information AND\n",
    "  - holding information\n",
    "- Examples:\n",
    "  - impact of trades on current holdings\n",
    "  - how transactions changed positions\n",
    "  - relationship between trades and holdings\n",
    "\n",
    "UNSUPPORTED:\n",
    "- Questions that CANNOT be answered from trades or holdings data\n",
    "- Examples:\n",
    "  - company executives\n",
    "  - market news\n",
    "  - predictions\n",
    "  - external facts\n",
    "  - vague or unrelated questions\n",
    "\n",
    "USER QUERY:\n",
    "\"{query}\"\n",
    "\n",
    "OUTPUT RULES (VERY IMPORTANT):\n",
    "- Output ONLY ONE label\n",
    "- Output must be EXACTLY one of:\n",
    "  TRADE_ONLY, HOLDING_ONLY, MIXED, UNSUPPORTED\n",
    "- Do NOT explain your reasoning\n",
    "- Do NOT add extra text\n",
    "- Do NOT add punctuation\n",
    "\"\"\"\n",
    "\n",
    "def resolve_intent(query: str) -> Dict[str, Any]:\n",
    "\n",
    "    \"\"\"Determines which datasets to query.\"\"\"\n",
    "\n",
    "    q_lower = query.lower()\n",
    "    \n",
    "    # Fast Path (Rule-Based)\n",
    "\n",
    "    if \"trade\" in q_lower and \"holding\" in q_lower:\n",
    "        return {\"intent\": \"MIXED\", \"use_trades\": True, \"use_holdings\": True}\n",
    "    \n",
    "    # Slow Path (LLM)\n",
    "    \n",
    "    res = GEN_MODEL.generate_content(INTENT_PROMPT.format(query=query))\n",
    "    intent = res.text.strip()\n",
    "    \n",
    "    return {\n",
    "        \"intent\": intent,\n",
    "        \"use_trades\": intent in [\"TRADE_ONLY\", \"MIXED\"],\n",
    "        \"use_holdings\": intent in [\"HOLDING_ONLY\", \"MIXED\"]\n",
    "    }\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a51d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Vector Retrieval\n",
    "\n",
    "def retrieve_context(query: str, plan: Dict[str, Any]) -> Optional[str]:\n",
    "    \"\"\"Fetches relevant rows from CSVs based on vector similarity.\"\"\"\n",
    "    \n",
    "    # 1. Embed & Reduce\n",
    "    query_emb = get_query_embedding(query)\n",
    "    query_pca = pca.apply_py(query_emb.reshape(1, -1))\n",
    "    \n",
    "    context_lines = []\n",
    "    \n",
    "    # 2. Search Trades\n",
    "    if plan['use_trades']:\n",
    "        distances, indices = trades_index.search(query_pca, k=5)\n",
    "        for idx in indices[0]:\n",
    "            if idx != -1:\n",
    "                row_str = trades_data.iloc[idx].to_string()\n",
    "                context_lines.append(f\"TRADE DATA:\\n{row_str}\")\n",
    "\n",
    "    # 3. Search Holdings\n",
    "\n",
    "    if plan['use_holdings']:\n",
    "        distances, indices = holdings_index.search(query_pca, k=5)\n",
    "        \n",
    "        for idx in indices[0]:\n",
    "            if idx != -1:\n",
    "                row_str = holdings_data.iloc[idx].to_string()\n",
    "                context_lines.append(f\"HOLDING DATA:\\n{row_str}\")\n",
    "                \n",
    "    return \"\\n---\\n\".join(context_lines) if context_lines else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5191503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Generation Layer (Human-Like Assistant)\n",
    "# -------------------------------\n",
    "\n",
    "import re\n",
    "\n",
    "ANSWER_PROMPT = \"\"\"\n",
    "You are a senior financial analyst explaining insights to a colleague in a chat.\n",
    "\n",
    "Your task is to answer in a **natural, conversational, human way** â€”\n",
    "as if you are speaking on a call or WhatsApp.\n",
    "\n",
    "NON-NEGOTIABLE RULES:\n",
    "- Start directly with the answer. Do NOT add titles or headings.\n",
    "- Do NOT use labels like \"Direct Answer\", \"Key Details\", \"Summary\", or \"Analysis\".\n",
    "- Do NOT use bullet points, numbered lists, or tables.\n",
    "- Write in short, flowing paragraphs.\n",
    "- Use ONLY the provided context.\n",
    "- Do NOT mention internal IDs, database fields, or system terms.\n",
    "\n",
    "STYLE GUIDELINES:\n",
    "- Merge facts into sentences.\n",
    "- Use human-friendly numbers:\n",
    "  - \"$18 million\" instead of \"$18,000,000\"\n",
    "  - \"1.8 million units\" instead of \"1,800,000 units\"\n",
    "- If allocations matter, explain them in plain language.\n",
    "\n",
    "STRICT REFUSAL:\n",
    "If the context does NOT clearly contain the answer, respond with EXACTLY:\n",
    "\"Sorry can not find the answer\"\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def clean_llm_answer(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Deterministically removes report-style artifacts\n",
    "    in case the LLM sneaks them in.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r\"\\*\\*Direct Answer:\\*\\*\",\n",
    "        r\"\\*\\*Key Details:\\*\\*\",\n",
    "        r\"\\*\\*Summary:\\*\\*\",\n",
    "        r\"\\*\\*Analysis:\\*\\*\",\n",
    "        r\"Direct Answer:\",\n",
    "        r\"Key Details:\",\n",
    "        r\"Summary:\",\n",
    "        r\"Analysis:\"\n",
    "    ]\n",
    "\n",
    "    for p in patterns:\n",
    "        text = re.sub(p, \"\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Collapse excessive newlines\n",
    "    text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def generate_answer(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Pipeline: Intent -> Retrieve -> Generate (Human-like)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Intent\n",
    "    plan = resolve_intent(query)\n",
    "\n",
    "    if plan[\"intent\"] == \"UNSUPPORTED\":\n",
    "        return \"Sorry can not find the answer\"\n",
    "\n",
    "    # 2. Retrieval\n",
    "    context_text = retrieve_context(query, plan)\n",
    "\n",
    "    if not context_text:\n",
    "        return \"Sorry can not find the answer\"\n",
    "\n",
    "    # 3. Generation\n",
    "    prompt = ANSWER_PROMPT.format(\n",
    "        context=context_text,\n",
    "        question=query\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        response = GEN_MODEL.generate_content(prompt)\n",
    "        raw_answer = response.text.strip()\n",
    "\n",
    "        # Post-process to enforce human tone\n",
    "        return clean_llm_answer(raw_answer)\n",
    "\n",
    "    except Exception:\n",
    "        return \"Sorry can not find the answer\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0624440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: **Direct Answer:**\n",
      "The most significant 'Buy' trade, based on principal value, is for **1.8M units** of **1083 HK** (Ticker: 1083) executed on **Jan 15, 2026**, amounting to **$18M**.\n",
      "\n",
      "**Key Details:**\n",
      "*   **Trade ID:** 4248444\n",
      "*   **Security:** 1083 HK (Ticker: 1083, ISIN: KYG8972T1067)\n",
      "*   **Trade Date:** Jan 15, 2026\n",
      "*   **Total Quantity Purchased:** 1.8M units\n",
      "*   **Price per Unit:** $10.00\n",
      "*   **Total Principal:** $18M\n",
      "*   **Counterparty:** ABGS\n",
      "*   **Custom Allocation:** Yes\n",
      "*   **Allocations Breakdown:**\n",
      "\n",
      "| Portfolio | Allocated Quantity | Allocated Principal |\n",
      "| :-------- | :----------------- | :------------------ |\n",
      "| Account A | 1.8M units         | $18M                |\n"
     ]
    }
   ],
   "source": [
    "# Interactive Loop\n",
    "\n",
    "print(\"Financial Engine Ready. Type 'exit' to quit.\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter Query: \")\n",
    "    if user_input.lower() == 'exit':\n",
    "        break\n",
    "        \n",
    "    answer = generate_answer(user_input)\n",
    "    print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
